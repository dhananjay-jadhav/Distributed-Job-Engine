# Distributed Job Engine

A modern distributed job processing engine built with NestJS, GraphQL Federation, gRPC, and PostgreSQL. This project implements a scalable microservices architecture for dynamic job execution and management with type-safe APIs and database access.

## ğŸ“Š Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           Client Application                         â”‚
â”‚                     (Web/Mobile/API Consumer)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚ HTTP/GraphQL
                            â”‚ Port: 4000
                            â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   Apollo Router       â”‚
                â”‚   (Supergraph)        â”‚
                â”‚   - Query Planning    â”‚
                â”‚   - Federation        â”‚
                â”‚   - Response Merge    â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                   â”‚                   â”‚
        â–¼                   â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Auth Service â”‚   â”‚ Jobs Service â”‚   â”‚   Future     â”‚
â”‚  Port: 3000   â”‚   â”‚ Port: 3001   â”‚   â”‚  Services    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                  â”‚
        â”‚ GraphQL          â”‚ GraphQL
        â”‚ Federation v2    â”‚ Federation v2
        â”‚                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
â”‚   GraphQL Subgraph Layer         â”‚
â”‚   (Apollo Federation v2)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚                   â”‚
     â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Auth   â”‚        â”‚  Jobs    â”‚
â”‚  API    â”‚        â”‚  API     â”‚
â”‚         â”‚        â”‚          â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â” â”‚        â”‚ â”Œâ”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚Loginâ”‚ â”‚        â”‚ â”‚Jobs  â”‚ â”‚
â”‚ â”‚User â”‚ â”‚        â”‚ â”‚Exec  â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”˜ â”‚        â”‚ â””â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚                  â”‚
     â”‚ gRPC             â”‚ Auth Check
     â”‚                  â”‚
â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Auth Service â”‚   â”‚  Jobs Service â”‚
â”‚  (Business)  â”‚   â”‚   (Business)  â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                      â”‚
     â”‚ Prisma ORM           â”‚ Event Publishing
     â”‚                      â”‚
â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL   â”‚      â”‚ Apache Pulsar â”‚
â”‚   Database    â”‚      â”‚ Message Brokerâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Supporting Services             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ Apollo Router (Federation Gateway)   â”‚
â”‚  â€¢ Pino Logger (Structured Logging)     â”‚
â”‚  â€¢ New Relic (APM & Monitoring)         â”‚
â”‚  â€¢ JWT Auth (Passport Strategy)         â”‚
â”‚  â€¢ Apache Pulsar (Event Streaming)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ Functional Workflow

### 1ï¸âƒ£ User Authentication Flow
```
â”Œâ”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Clientâ”‚â”€â”€â”€â”€â”€â–¶â”‚Auth Serviceâ”‚â”€â”€â”€â”€â”€â–¶â”‚Auth Logicâ”‚â”€â”€â”€â”€â”€â–¶â”‚PostgreSQLâ”‚
â””â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚              â”‚                     â”‚                 â”‚
    â”‚  GraphQL     â”‚                     â”‚                 â”‚
    â”‚  login()     â”‚   Validate          â”‚   Query User    â”‚
    â”‚              â”‚   Credentials       â”‚   & Password    â”‚
    â”‚              â”‚                     â”‚                 â”‚
    â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
    â”‚  JWT Token   â”‚                     â”‚                 â”‚
    â”‚  + User Data â”‚                     â”‚                 â”‚
```

**Steps:**
1. Client sends login credentials via GraphQL mutation
2. Auth service validates credentials against PostgreSQL (via Prisma)
3. On success, JWT token is generated and returned
4. Client stores JWT for subsequent authenticated requests

### 2ï¸âƒ£ User Creation Flow
```
â”Œâ”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Clientâ”‚â”€â”€â”€â”€â”€â–¶â”‚Auth Serviceâ”‚â”€â”€â”€â”€â”€â–¶â”‚User Logicâ”‚â”€â”€â”€â”€â”€â–¶â”‚PostgreSQLâ”‚
â””â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚              â”‚                     â”‚                 â”‚
    â”‚  GraphQL     â”‚   JWT Auth          â”‚                 â”‚
    â”‚  createUser()â”‚   Guard Check       â”‚   Create User   â”‚
    â”‚  + JWT       â”‚                     â”‚   Record        â”‚
    â”‚              â”‚                     â”‚                 â”‚
    â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
    â”‚  User Data   â”‚                     â”‚                 â”‚
```

**Steps:**
1. Client sends createUser mutation with JWT token
2. Auth guard validates JWT token via gRPC
3. User service creates new user in PostgreSQL
4. New user data is returned to client

### 3ï¸âƒ£ Job Execution Flow
```
â”Œâ”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Clientâ”‚â”€â”€â”€â”€â”€â–¶â”‚Jobs Serviceâ”‚â”€â”€â”€â”€â”€â–¶â”‚Jobs Discoveryâ”‚â”€â”€â”€â”€â”€â–¶â”‚Job Engineâ”‚
â””â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚              â”‚                      â”‚                    â”‚
    â”‚  GraphQL     â”‚   JWT Auth           â”‚   Find Job by      â”‚
    â”‚  executeJob()â”‚   Guard Check        â”‚   Name/Metadata    â”‚
    â”‚  + JWT       â”‚   (via gRPC)         â”‚                    â”‚
    â”‚              â”‚                      â”‚                    â”‚
    â”‚              â”‚                      â”‚   Execute Job â”€â”€â”€â”€â–¶â”‚
    â”‚              â”‚                      â”‚                    â”‚
    â”‚              â”‚                      â”‚                    â”‚ Publish Event
    â”‚              â”‚                      â”‚                    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚              â”‚                      â”‚                    â”‚            â”‚
    â”‚              â”‚                      â”‚                    â”‚            â–¼
    â”‚              â”‚                      â”‚                    â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚              â”‚                      â”‚                    â”‚    â”‚Apache Pulsar â”‚
    â”‚              â”‚                      â”‚                    â”‚    â”‚   Topic      â”‚
    â”‚              â”‚                      â”‚                    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
    â”‚  Job Result  â”‚                      â”‚                    â”‚
```

**Steps:**
1. Client sends executeJob mutation with job name and JWT token
2. Jobs service validates JWT via gRPC call to Auth service
3. Jobs discovery system finds the job by name using metadata
4. Job is executed and publishes event to Apache Pulsar topic
5. Job result is returned to client

### 4ï¸âƒ£ List Jobs Flow
```
â”Œâ”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Clientâ”‚â”€â”€â”€â”€â”€â–¶â”‚Jobs Serviceâ”‚â”€â”€â”€â”€â”€â–¶â”‚Jobs Discoveryâ”‚
â””â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚              â”‚                      â”‚
    â”‚  GraphQL     â”‚   JWT Auth           â”‚   Get All Jobs
    â”‚  jobs()      â”‚   Guard Check        â”‚   Metadata
    â”‚  + JWT       â”‚   (via gRPC)         â”‚
    â”‚              â”‚                      â”‚
    â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
    â”‚  Jobs List   â”‚                      â”‚
    â”‚  (Metadata)  â”‚                      â”‚
```

**Steps:**
1. Client sends jobs query with optional filter and JWT token
2. Jobs service validates JWT via gRPC call to Auth service
3. Jobs discovery returns list of available jobs with metadata
4. Jobs list is returned to client

## ğŸš€ Features

- **Microservices Architecture**: Built using NestJS with Nx monorepo for scalable microservices
- **Apollo Router Supergraph**: High-performance GraphQL gateway for unified API access
- **Authentication System**: JWT-based authentication with GraphQL Federation and gRPC
- **Job Processing Engine**: Dynamic job discovery and execution system with metadata-driven architecture
- **Event-Driven Architecture**: Apache Pulsar integration for reliable event streaming and message publishing
- **GraphQL Federation**: Apollo Federation v2 for distributed GraphQL architecture
- **Database Management**: PostgreSQL with Prisma ORM for type-safe database access
- **Observability**: Integrated logging with Pino and monitoring with New Relic
- **Modern Stack**: TypeScript, NestJS, GraphQL, gRPC, Prisma, Apache Pulsar

## ğŸ› ï¸ Technologies

- **Backend Framework**: NestJS
- **Monorepo Tool**: Nx
- **API Gateway**: Apollo Router
- **API**: GraphQL with Apollo Federation v2
- **Authentication**: JWT with Passport
- **Database**: PostgreSQL
- **ORM**: Prisma
- **Communication**: gRPC with Protocol Buffers
- **Message Broker**: Apache Pulsar
- **Logging**: Pino (nestjs-pino)
- **Monitoring**: New Relic
- **Language**: TypeScript
- **Container Orchestration**: Docker Compose, Kubernetes
- **Cloud Provider**: AWS

## ğŸ“‹ Prerequisites

- Node.js (v20 or later)
- Yarn package manager (v4.10.3 or later)
- Docker and Docker Compose
- Apollo Rover CLI (for composing the supergraph schema)
- PostgreSQL (or use Docker Compose setup)
- Apache Pulsar (or use Docker Compose setup)
- Kubernetes cluster (optional, for production deployment)
- AWS Account (optional, for cloud deployment)

## ğŸ”§ Installation

1. Clone the repository:

```bash
git clone https://github.com/dhananjay-jadhav/Distributed-Job-Engine.git
cd Distributed-Job-Engine
```

2. Install dependencies:

```bash
yarn install
```

3. Set up environment variables:

```bash
# Copy example environment file
cp .env.sample .env

# Configure the following variables
DATABASE_URL=postgres://postgres:admin@localhost:5432/auth
USER_PORT=3000
JOBS_PORT=3001
AUTH_JWT_SECRET=your_jwt_secret
AUTH_JWT_EXPIRES_IN=300

# Apache Pulsar configuration
PULSAR_SERVICE_URLS=pulsar://localhost:6650

# Optional: New Relic configuration
NEW_RELIC_AI_MONITORING_ENABLED=true
NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED=100k
NEW_RELIC_SPAN_EVENTS_MAX_SAMPLES_STORED=10k
NEW_RELIC_APP_NAME=Distributed-Job-Engine
NEW_RELIC_LICENSE_KEY=your_license_key
NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true
```

4. Start PostgreSQL and Apache Pulsar (using Docker Compose):

```bash
docker-compose up -d
```

This will start:
- PostgreSQL database on port 5432
- Apache Pulsar broker on port 6650
- Pulsar Manager dashboard on port 9527 (accessible at http://localhost:9527)

5. Run database migrations:

```bash
yarn auth-migrate
```

6. Install Apollo Rover CLI (for composing the supergraph):

**Recommended (via curl):**
```bash
curl -sSL https://rover.apollo.dev/nix/latest | sh
```

**Alternative (via npm):**
```bash
npm install -g @apollo/rover
```

> **Note**: Yarn 4+ doesn't support `yarn global`. Use curl (recommended) or npm for global CLI tools.

**Verify installation:**
```bash
rover --version
```

## ğŸš€ Running the Application

### Development Mode

1. Start the authentication service:

```bash
yarn nx serve auth-api
# Runs on http://localhost:3000/api
```

2. Start the jobs service:

```bash
yarn nx serve jobs-api
# Runs on http://localhost:3001/api
```

3. Compose the supergraph schema and start Apollo Router:

```bash
# Compose the supergraph schema from subgraphs
cd apps/router
./compose-supergraph.sh

# Start the Apollo Router
cd ../..
docker compose up router
# Runs on http://localhost:4000
```

**Access the unified GraphQL API:**
- Apollo Router: http://localhost:4000
- Health Check: http://localhost:8088/health

### Alternative: Direct Subgraph Access (without Router)

You can also access subgraphs directly during development:
- Auth Service: http://localhost:3000/api/graphql
- Jobs Service: http://localhost:3001/api/graphql

### Building for Production

Build all applications:

```bash
yarn nx build auth-api
yarn nx build jobs-api
```

### Testing

Run tests for all projects:

```bash
yarn all:test
```

Run tests for a specific project:

```bash
yarn nx test auth
yarn nx test jobs
```

### Linting

Lint all projects:

```bash
yarn all:lint
```

Lint a specific project:

```bash
yarn nx lint auth-api
```

### Code Formatting

Format code using Prettier:

```bash
yarn format
```

## ğŸ§ª Comprehensive Testing

This project includes comprehensive tests with minimal mocking, using real database instances for integration testing.

### Quick Start

1. Start the database:
```bash
docker compose up -d
```

2. Run migrations:
```bash
yarn nx migrate-prisma auth-db
```

3. Run all tests:
```bash
yarn nx run-many -t test
```

For detailed testing instructions, see [TESTING.md](TESTING.md).

### Test Coverage

- âœ… Unit tests with real database integration
- âœ… Service layer tests
- âœ… Resolver and controller tests
- âœ… E2E tests for GraphQL API
- âœ… GitHub Actions CI with parallel jobs and PostgreSQL service

## ğŸ—ï¸ Project Structure

```
.
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ auth-api/            # Authentication service (GraphQL + gRPC)
â”‚   â”‚   â”œâ”€â”€ src/auth/       # Auth resolvers and controllers
â”‚   â”‚   â”œâ”€â”€ src/users/      # Users resolvers
â”‚   â”‚   â””â”€â”€ src/health/     # Health check endpoints
â”‚   â”œâ”€â”€ auth-api-e2e/       # E2E tests for auth service
â”‚   â”œâ”€â”€ jobs-api/           # Jobs service (GraphQL)
â”‚   â”‚   â”œâ”€â”€ src/api/        # Jobs resolvers
â”‚   â”‚   â””â”€â”€ src/health/     # Health check endpoints
â”‚   â”œâ”€â”€ jobs-api-e2e/       # E2E tests for jobs service
â”‚   â””â”€â”€ router/             # Apollo Router configuration
â”‚       â”œâ”€â”€ router.yaml     # Router configuration
â”‚       â”œâ”€â”€ Dockerfile      # Docker image for router
â”‚       â”œâ”€â”€ compose-supergraph.sh  # Schema composition script
â”‚       â””â”€â”€ README.md       # Router documentation
â”œâ”€â”€ libs/
â”‚   â”œâ”€â”€ apache-pulsar/      # Apache Pulsar client integration
â”‚   â”œâ”€â”€ auth-db/            # Database module with Prisma
â”‚   â”œâ”€â”€ auth/               # Authentication business logic and guards
â”‚   â”œâ”€â”€ common-utils/       # Shared utilities, types, and DTOs
â”‚   â”œâ”€â”€ jobs/               # Jobs execution engine and discovery
â”‚   â”œâ”€â”€ proto/              # Protocol Buffers definitions for gRPC
â”‚   â””â”€â”€ users/              # Users business logic
â”œâ”€â”€ docker-compose.yaml     # Services: PostgreSQL, Pulsar, Router
â””â”€â”€ README.md
```

## ğŸ“– API Documentation

The project uses GraphQL Federation with multiple services unified through Apollo Router.

### Apollo Router (Supergraph)
**Unified GraphQL endpoint:** `http://localhost:4000`

This is the recommended entry point for all GraphQL queries. The router automatically:
- Routes queries to appropriate subgraphs (auth-api, jobs-api)
- Handles query planning and execution
- Merges responses from multiple subgraphs
- Provides a unified schema across all services

**Example unified query:**
```graphql
query {
  # From auth subgraph
  user(userId: "user-id") {
    id
    email
  }
  
  # From jobs subgraph
  jobs {
    name
    description
  }
}
```

**Access points:**
- GraphQL API: `http://localhost:4000`
- Health Check: `http://localhost:8088/health`
- Interactive Explorer: `http://localhost:4000` (in browser)

### Authentication Service (Subgraph)
Direct GraphQL endpoint: `http://localhost:3000/api/graphql`

**Mutations:**
- `login(loginInput: LoginInput!)`: Authenticate user and receive JWT token
- `createUser(createUserInput: CreateUserInput!)`: Create a new user (requires authentication)

**Queries:**
- `user(userId: String!)`: Get user by ID (requires authentication)

### Jobs Service (Subgraph)
Direct GraphQL endpoint: `http://localhost:3001/api/graphql`

**Queries:**
- `jobs(jobsFilter: JobsFilter)`: List all available jobs with optional filtering (requires authentication)

**Mutations:**
- `executeJob(jobName: String!)`: Execute a job by name (requires authentication)

### GraphQL Playground

**Recommended:** Use the Apollo Router endpoint for a unified experience:
- **Router:** `http://localhost:4000` (unified access to all services)

**For development/debugging:** Access subgraphs directly:
- **Auth:** `http://localhost:3000/api/graphql`
- **Jobs:** `http://localhost:3001/api/graphql`

For detailed router configuration and advanced usage, see [apps/router/README.md](apps/router/README.md).

## ğŸ“® Apache Pulsar Integration

The project integrates Apache Pulsar for event-driven architecture and message streaming.

### Purpose

Apache Pulsar is used to publish job execution events, enabling:
- **Asynchronous Processing**: Decouple job execution from event handling
- **Event Streaming**: Stream job execution results to downstream consumers
- **Scalability**: Handle high-throughput event publishing with Pulsar's distributed architecture
- **Reliability**: Guaranteed message delivery with Pulsar's persistent storage

### Architecture

All jobs extend `AbstractJob` which provides built-in Pulsar integration:

```typescript
@Jobs({
  name: 'Fibonacci',
  description: 'Generate a Fibonacci sequence and store it in DB',
})
export class FibonacciJob extends AbstractJob {
  constructor(pulsarProducerClient: PulsarProducerClient) {
    super(pulsarProducerClient);
  }
}
```

When a job executes, it automatically publishes events to a specified Pulsar topic.

### Configuration

Configure Pulsar connection in your `.env` file:

```bash
PULSAR_SERVICE_URLS=pulsar://localhost:6650
```

### Pulsar Manager Dashboard

Access the Pulsar Manager dashboard to monitor topics, messages, and cluster health:
- URL: `http://localhost:9527`
- Dashboard provides visibility into message flows, throughput, and consumer groups

### Docker Setup

The `docker-compose.yaml` includes:
- **Pulsar Broker**: Standalone mode on port 6650
- **Pulsar Manager**: Web UI for cluster management on port 9527

```bash
docker-compose up -d pulsar
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¥ Authors

- **Dhananjay Jadhav** -

## ğŸŒŸ Acknowledgments

- NestJS Team for the excellent framework
- Apollo GraphQL for Federation support
- Nx team for the powerful monorepo tools
- Prisma team for the amazing ORM
